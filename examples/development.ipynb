{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2396234a-887d-4737-92e8-2805cc5cb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from typing import Dict\n",
    "\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark import keyword_only\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.ml import Estimator\n",
    "from pyspark.ml.pipeline import Model\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.param.shared import (\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    Param,\n",
    "    Params,\n",
    "    TypeConverters,\n",
    ")\n",
    "\n",
    "from pyspark_encoders._session import get_dataframe_spark_session\n",
    "\n",
    "spark = SparkSession.builder.appName(\"mySparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b4bc9ea-c04f-4c5d-bf24-af366d651c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatboostEncoder(\n",
    "    Estimator,\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    DefaultParamsReadable,\n",
    "    DefaultParamsWritable,\n",
    "):\n",
    "\n",
    "    a = Param(\n",
    "        Params._dummy(),\n",
    "        \"a\",\n",
    "        \"Parameter a\",\n",
    "        typeConverter=TypeConverters.toFloat,\n",
    "    )\n",
    "\n",
    "    sigma = Param(\n",
    "        Params._dummy(),\n",
    "        \"sigma\",\n",
    "        \"Parameter sigma\",\n",
    "        typeConverter=TypeConverters.toFloat,\n",
    "    )\n",
    "\n",
    "    targetCol = Param(\n",
    "        Params._dummy(),\n",
    "        \"targetCol\",\n",
    "        \"The target column name\",\n",
    "        typeConverter=TypeConverters.toString,\n",
    "    )\n",
    "\n",
    "    avgTarget = Param(\n",
    "        Params._dummy(),\n",
    "        \"avgTarget\",\n",
    "        \"Average value of target\",\n",
    "        typeConverter=TypeConverters.toFloat,\n",
    "    )\n",
    "\n",
    "    unique_train = None\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, targetCol=None, a=1, sigma=None):\n",
    "        super().__init__()\n",
    "        self._setDefault(targetCol=None, a=1, sigma=None, avgTarget=None)\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, targetCol=None, a=1, sigma=None, avgTarget=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setInputCol(self, new_inputCol):\n",
    "        \"\"\"\n",
    "        Setter for `inputCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(inputCol=new_inputCol)\n",
    "\n",
    "    def setOutputCol(self, new_outputCol):\n",
    "        \"\"\"\n",
    "        Setter for `outputCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(outputCol=new_outputCol)\n",
    "\n",
    "    def setTargetCol(self, new_targetCol):\n",
    "        \"\"\"\n",
    "        Setter for `targetCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(targetCol=new_targetCol)\n",
    "\n",
    "    def getTargetCol(self):\n",
    "        \"\"\"\n",
    "        Getter for `targetCol`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.targetCol)\n",
    "\n",
    "    def setA(self, new_a):\n",
    "        \"\"\"\n",
    "        Setter for `a`\n",
    "        \"\"\"\n",
    "        return self.setParams(a=new_a)\n",
    "\n",
    "    def getA(self):\n",
    "        \"\"\"\n",
    "        Getter for `a`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.a)\n",
    "\n",
    "    def setSigma(self, new_sigma):\n",
    "        \"\"\"\n",
    "        Setter for `sigma`\n",
    "        \"\"\"\n",
    "        return self.setParams(sigma=new_sigma)\n",
    "\n",
    "    def getSigma(self):\n",
    "        \"\"\"\n",
    "        Getter for `sigma`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.sigma)\n",
    "\n",
    "    def setAvgTarget(self, new_avgTarget):\n",
    "        \"\"\"\n",
    "        Setter for `sigma`\n",
    "        \"\"\"\n",
    "        return self.setParams(avgTarget=new_avgTarget)\n",
    "\n",
    "    def getAvgTarget(self):\n",
    "        \"\"\"\n",
    "        Getter for `sigma`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.avgTarget)\n",
    "\n",
    "    def _fit(self, dataset):\n",
    "        \"\"\"\n",
    "        Fits the CatboostEncoder to the input dataset\n",
    "        \"\"\"\n",
    "        input_col = self.getInputCol()\n",
    "        output_col = self.getOutputCol()\n",
    "        target_col = self.getTargetCol()\n",
    "        a = self.getA()\n",
    "        sigma = self.getSigma()\n",
    "        avgTarget = self.getAvgTarget()\n",
    "\n",
    "        ymean = df.select(sf.avg(target_col)).collect()[0][0]\n",
    "        self.setAvgTarget(ymean)\n",
    "        \n",
    "        colmap = (\n",
    "            df\n",
    "            .select(input_col, target_col)\n",
    "            .groupby(input_col)\n",
    "            .agg(sf.sum(target_col).alias(\"sum\"), sf.count(target_col).alias(\"count\"))\n",
    "            .toPandas()\n",
    "            .set_index(input_col)\n",
    "        )\n",
    "\n",
    "        self.unique_train = colmap.index\n",
    "\n",
    "        print(colmap, self.unique_train)\n",
    "\n",
    "        estimates = {i: 1 for i, row in colmap.iterrows()}\n",
    "\n",
    "        print(estimates)\n",
    "\n",
    "        return CatboostEncoderModel(\n",
    "            inputCol=input_col,\n",
    "            outputCol=output_col,\n",
    "            targetCol=target_col,\n",
    "            categoriesTargetEstimates=estimates,\n",
    "        )\n",
    "\n",
    "\n",
    "class CatboostEncoderModel(\n",
    "    Model,\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    DefaultParamsReadable,\n",
    "    DefaultParamsWritable,\n",
    "):\n",
    "    targetCol = Param(\n",
    "        Params._dummy(),\n",
    "        \"targetCol\",\n",
    "        \"The target column name\",\n",
    "        typeConverter=TypeConverters.toString,\n",
    "    )\n",
    "\n",
    "    categoriesTargetEstimates = Param(\n",
    "        Params._dummy(),\n",
    "        \"categoriesTargetEstimates\",\n",
    "        \"Target estimation for each category class\",\n",
    "    )\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputCol: str = None,\n",
    "        outputCol: str = None,\n",
    "        targetCol: str = None,\n",
    "        categoriesTargetEstimates: Dict[str, float] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._setDefault(targetCol=None)\n",
    "        self._setDefault(categoriesTargetEstimates=None)\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(\n",
    "        self,\n",
    "        inputCol: str = None,\n",
    "        outputCol: str = None,\n",
    "        targetCol: str = None,\n",
    "        categoriesTargetEstimates: Dict[str, float] = None,\n",
    "    ):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setInputCol(self, new_inputCol: str) -> None:\n",
    "        \"\"\"\n",
    "        Setter for `inputCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(inputCol=new_inputCol)\n",
    "\n",
    "    def setOutputCol(self, new_outputCol: str) -> None:\n",
    "        \"\"\"\n",
    "        Setter for `outputCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(outputCol=new_outputCol)\n",
    "\n",
    "    def setTargetCol(self, new_targetCol: str) -> None:\n",
    "        \"\"\"\n",
    "        Setter for `targetCol`\n",
    "        \"\"\"\n",
    "        return self.setParams(targetCol=new_targetCol)\n",
    "\n",
    "    def setCategoriesTargetEstimates(\n",
    "        self, new_categoriesTargetEstimates: Dict[str, float]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Setter for `categoriesTargetEstimates`\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(new_categoriesTargetEstimates, dict):\n",
    "            raise TypeError(\"The parameter `categoriesTargetEstimates` must be a dict.\")\n",
    "\n",
    "        if len(new_categoriesTargetEstimates) < 1:\n",
    "            raise ValueError(\n",
    "                \"The parameter `categoriesTargetEstimates` cannot be empty.\"\n",
    "            )\n",
    "\n",
    "        return self.setParams(categoriesTargetEstimates=new_categoriesTargetEstimates)\n",
    "\n",
    "    def getTargetCol(self) -> str:\n",
    "        \"\"\"\n",
    "        Getter for `targetCol`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.targetCol)\n",
    "\n",
    "    def getCategoriesTargetEstimates(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Getter for `categoriesTargetEstimates`\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.categoriesTargetEstimates)\n",
    "\n",
    "    def _transform(self, dataset) -> DataFrame:\n",
    "        input_col = self.getInputCol()\n",
    "        output_col = self.getOutputCol()\n",
    "        categories_target_estimates = self.getCategoriesTargetEstimates()\n",
    "        spark = get_dataframe_spark_session(dataset)\n",
    "        df_estimates = spark.createDataFrame(\n",
    "            categories_target_estimates.items(), [input_col, output_col]\n",
    "        )\n",
    "        return dataset.join(df_estimates, on=input_col, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89fcaf74-7f58-47e1-8871-7b2d0902efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|catColumn|targetColumn|\n",
      "+---------+------------+\n",
      "|        A|           1|\n",
      "|        A|           2|\n",
      "|        B|           6|\n",
      "|        B|           4|\n",
      "|        A|           3|\n",
      "|        B|           5|\n",
      "+---------+------------+\n",
      "\n",
      "           sum  count\n",
      "catColumn            \n",
      "A            6      3\n",
      "B           15      3 Index(['A', 'B'], dtype='object', name='catColumn')\n",
      "{'A': 1, 'B': 1}\n",
      "+---------+------------+------------+\n",
      "|catColumn|targetColumn|encCatColumn|\n",
      "+---------+------------+------------+\n",
      "|        A|           1|           1|\n",
      "|        A|           2|           1|\n",
      "|        B|           6|           1|\n",
      "|        B|           4|           1|\n",
      "|        A|           3|           1|\n",
      "|        B|           5|           1|\n",
      "+---------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values = [(\"A\", 1), (\"A\", 2), (\"B\", 6), (\"B\", 4), (\"A\", 3), (\"B\", 5)]\n",
    "\n",
    "df = spark.createDataFrame(values, [\"catColumn\", \"targetColumn\"])\n",
    "df.show()\n",
    "\n",
    "encoder = CatboostEncoder(\n",
    "    inputCol=\"catColumn\",\n",
    "    outputCol=\"encCatColumn\",\n",
    "    targetCol=\"targetColumn\",\n",
    "    a=1\n",
    ")\n",
    "\n",
    "encoder_model = encoder.fit(df)\n",
    "\n",
    "transf_df = encoder_model.transform(df)\n",
    "\n",
    "transf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba820032-4218-4fde-9017-e502c1f95e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B'], dtype='object', name='catColumn')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.unique_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "707655be-b97d-46f1-8ace-588bbefcb2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[catColumn       A\n",
       " targetColumn    1\n",
       " Name: 0, dtype: object,\n",
       " catColumn       A\n",
       " targetColumn    2\n",
       " Name: 1, dtype: object,\n",
       " catColumn       B\n",
       " targetColumn    6\n",
       " Name: 2, dtype: object,\n",
       " catColumn       B\n",
       " targetColumn    4\n",
       " Name: 3, dtype: object,\n",
       " catColumn       A\n",
       " targetColumn    3\n",
       " Name: 4, dtype: object,\n",
       " catColumn       B\n",
       " targetColumn    5\n",
       " Name: 5, dtype: object]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row for i, row in df.toPandas().iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516e183-1965-480a-a415-3eb62f25fc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
